# Server Configuration
PORT=8080

# Database
DATABASE_URL=postgres://postgres:postgres@localhost:5432/crossplay?sslmode=disable

# Redis
REDIS_URL=redis://localhost:6379

# JWT Secret (change in production!)
JWT_SECRET=your-secret-key-change-in-production

# ===========================================
# LLM Configuration for Puzzle Generation
# ===========================================

# LLM Provider: "openai" (for local LLMs like LMStudio, Ollama) or "anthropic"
LLM_PROVIDER=openai

# LLM API URL (defaults based on provider)
# For local LLMs (LMStudio): http://localhost:1234/v1/chat/completions
# For Ollama: http://localhost:11434/v1/chat/completions
# For Anthropic: https://api.anthropic.com/v1/messages
LLM_API_URL=http://localhost:1234/v1/chat/completions

# LLM API Key (optional for local LLMs, required for cloud providers)
# For local LLMs, you can leave this empty or use any value
LLM_API_KEY=

# LLM Model Name
# For local LLMs: use the model name loaded in LMStudio/Ollama
# For Anthropic: claude-sonnet-4-20250514
LLM_MODEL=local-model

# LLM Request Timeout (default: 120s - local models may need more time)
LLM_TIMEOUT=180s

# LLM Max Tokens (default: 4096)
LLM_MAX_TOKENS=4096

# Legacy Anthropic API Key (for backward compatibility)
ANTHROPIC_API_KEY=

# ===========================================
# Environment
# ===========================================
ENV=development
